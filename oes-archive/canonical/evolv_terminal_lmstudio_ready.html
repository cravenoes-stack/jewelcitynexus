<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>EvolvTerminal — LM Studio Ready (Offline-capable)</title>
  <style>
    :root{
      --bg:#0b1220; --panel:#0f1720; --muted:#9aa6b2; --cyan:#06b6d4; --purple:#7c3aed;
      font-family: Inter, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
    }
    html,body{height:100%; margin:0; background:linear-gradient(135deg,#05060a 0%, #0b1220 100%); color:#e6eef6;}
    .app{height:100vh; display:flex; flex-direction:column; gap:0; overflow:hidden;}
    .topbar{border-bottom:1px solid rgba(96,165,250,0.06); background:linear-gradient(90deg, rgba(6,182,212,0.04), rgba(124,58,237,0.03)); backdrop-filter: blur(6px);}
    .topbar .inner{padding:12px 18px; display:flex; align-items:center; gap:12px;}
    .cognitive {display:flex; gap:8px; overflow:auto; padding-left:6px;}
    .cog-item{flex:0 0 auto; padding:8px 12px; border-radius:8px; background:rgba(15,23,42,0.5); border:1px solid rgba(6,182,212,0.08); margin-right:8px;}
    .main{flex:1; display:flex; min-height:0;}
    .sidebar{width:320px; border-right:1px solid rgba(255,255,255,0.03); background:rgba(15,23,42,0.45); display:flex; flex-direction:column; min-width:240px;}
    .rightbar{width:320px; border-left:1px solid rgba(255,255,255,0.03); background:rgba(15,23,42,0.45); display:flex; flex-direction:column;}
    .center{flex:1; display:flex; flex-direction:column; min-width:0;}
    .section{padding:14px; border-bottom:1px solid rgba(255,255,255,0.02);}
    .tasks .task{background:rgba(15,23,42,0.35); border-radius:8px; padding:8px; margin-bottom:8px;}
    .tabs{display:flex; gap:6px; align-items:center;}
    .tab{padding:6px 10px; border-radius:8px; background:rgba(10,14,20,0.4); cursor:pointer;}
    .tab.active{background:linear-gradient(90deg,#06202a,#15303a); border:1px solid rgba(6,182,212,0.08);}
    .header{display:flex; justify-content:space-between; align-items:center; gap:12px;}
    .messages{flex:1; overflow:auto; padding:18px; display:flex; flex-direction:column; gap:12px; background: linear-gradient(180deg, rgba(2,6,11,0.2), transparent);}
    .msg{max-width:70%; padding:12px 14px; border-radius:12px; box-shadow: 0 1px 0 rgba(255,255,255,0.02) inset;}
    .msg.user{margin-left:auto; background:linear-gradient(180deg,#0ea5a7,#075985); color:white;}
    .msg.ai{background:rgba(15,23,42,0.65); color:#e6eef6; border:1px solid rgba(99,102,241,0.06);}
    .msg.system{background:rgba(55,65,81,0.45); color:#d1d5db; border:1px solid rgba(124,58,237,0.06);}
    .inputbar{padding:12px; border-top:1px solid rgba(255,255,255,0.02); display:flex; gap:8px; align-items:flex-end; background:rgba(2,6,11,0.35);}
    textarea{width:100%; min-height:48px; max-height:240px; resize:vertical; padding:10px; border-radius:10px; border:1px solid rgba(255,255,255,0.03); background:rgba(10,14,20,0.65); color:inherit; outline:none;}
    button.btn{background:linear-gradient(90deg,#06b6d4,#0ea5a7); border:none; padding:10px 14px; border-radius:10px; color:#022; font-weight:600; cursor:pointer;}
    .statusbar{padding:8px 12px; border-top:1px solid rgba(255,255,255,0.02); display:flex; justify-content:space-between; font-size:12px; color:var(--muted); align-items:center; background:rgba(2,6,11,0.45);}
    .small{font-size:12px; color:var(--muted);}
    .progress{height:8px; background:rgba(255,255,255,0.03); border-radius:6px; overflow:hidden;}
    .progress > i{display:block; height:100%; background:linear-gradient(90deg,var(--cyan),var(--purple)); width:30%;}
    .icon{width:18px; height:18px; display:inline-block; vertical-align:middle;}
    .flex{display:flex;}
    .gap{gap:8px;}
    .center-col{display:flex; flex-direction:column;}
    .scroll {overflow:auto;}
    .controls{display:flex; gap:8px; align-items:center;}
    .select, .input{background:rgba(255,255,255,0.02); border:1px solid rgba(255,255,255,0.03); color:inherit; padding:6px 8px; border-radius:8px;}
    .danger{background:linear-gradient(90deg,#ef4444,#f97316); color:white;}
    @media (max-width:980px){ .sidebar,.rightbar{display:none;} .main{padding:0;} }
  </style>
</head>
<body>
  <div class="app">
    <div class="topbar">
      <div class="inner">
        <div style="display:flex; align-items:center; gap:10px;">
          <svg class="icon" viewBox="0 0 24 24"><path fill="#06b6d4" d="M12 2L15 8l6 .5-4.5 3.5L18 20l-6-4-6 4 1.5-8L3 8.5 9 8z"/></svg>
          <strong style="color:var(--cyan)">Cognitive Mesh</strong>
        </div>
        <div style="margin-left:8px;" class="controls">
          <!-- Provider + Model selection -->
          <label class="small" style="margin-right:6px;">Provider</label>
          <select id="providerSelect" class="select">
            <option value="lmstudio">LM Studio</option>
            <option value="ollama">Ollama</option>
            <option value="off">Simulation</option>
          </select>
          <label class="small" style="margin-left:8px;margin-right:6px;">Model</label>
          <select id="modelSelect" class="select" style="min-width:220px;">
            <option>loading...</option>
          </select>
          <button id="refreshModels" title="Refresh models" class="select">⟳</button>
          <label class="small" style="margin-left:8px;margin-right:6px;">Exec</label>
          <input id="execToggle" type="checkbox" title="Enable local executor" />
          <span class="small" id="execStatus" style="margin-left:6px;color:var(--muted)">executor off</span>
        </div>
      </div>
    </div>

    <div class="main">
      <aside class="sidebar">
        <div class="section">
          <div style="font-size:18px; color:var(--cyan); font-weight:600;" id="dateLabel"></div>
          <div class="small" id="weatherLabel">Richmond, VA • 72°F • Partly Cloudy</div>
        </div>

        <div class="section tasks">
          <div style="display:flex; align-items:center; gap:8px; margin-bottom:8px;">
            <svg class="icon" viewBox="0 0 24 24"><path fill="#f97316" d="M12 8V12L14 14"/></svg>
            <strong class="small" style="color:#e6eef6">Work & Deadlines</strong>
          </div>
          <div class="task"><div>OES Terminal Demo</div><div class="small">Due: Today, 6:00 PM</div></div>
          <div class="task"><div>Mobile Integration Review</div><div class="small">Tomorrow, 10:00 AM</div></div>
        </div>

        <div class="section">
          <div style="display:flex; align-items:center; gap:8px; margin-bottom:8px;">
            <svg class="icon" viewBox="0 0 24 24"><path fill="#06b6d4" d="M12 2a10 10 0 100 20 10 10 0 000-20z"/></svg>
            <strong class="small" style="color:#e6eef6">Personal & Growth</strong>
          </div>
          <div class="task"><div>Morning meditation</div></div>
          <div class="task"><div>Exercise routine</div></div>
        </div>

        <div class="section" style="flex:1; overflow:auto;">
          <div style="display:flex; align-items:center; gap:8px; margin-bottom:8px;">
            <svg class="icon" viewBox="0 0 24 24"><path fill="#8b5cf6" d="M3 3h18v4H3zM3 10h18v11H3z"/></svg>
            <strong class="small" style="color:#e6eef6">AI Task Queue</strong>
          </div>
          <div id="aiTasksArea"></div>
        </div>
      </aside>

      <main class="center">
        <div class="section header">
          <div style="display:flex; align-items:center; gap:12px;">
            <svg class="icon" viewBox="0 0 24 24"><path fill="#06b6d4" d="M3 12h18v2H3z"/></svg>
            <strong style="color:var(--cyan)">EvolvTerminal</strong>
            <div class="tabs" id="tabsArea"></div>
            <button title="New Tab" id="addTabBtn" style="background:none;border:1px solid rgba(255,255,255,0.02);padding:6px;border-radius:8px;color:var(--muted);cursor:pointer;margin-left:8px;">＋</button>
          </div>
          <div style="display:flex; align-items:center; gap:8px;">
            <button class="small" id="settingsBtn">Settings</button>
          </div>
        </div>

        <div id="messages" class="messages" role="log" aria-live="polite"></div>

        <div class="inputbar">
          <textarea id="inputBox" placeholder="Speak to your AI co-pilot... or use /command for direct execution"></textarea>
          <button id="sendBtn" class="btn">Send</button>
        </div>
      </main>

      <aside class="rightbar">
        <div class="section">
          <div style="display:flex; align-items:center; gap:8px;">
            <svg class="icon" viewBox="0 0 24 24"><path fill="#60a5fa" d="M21 6v10H3V6h18z"/></svg>
            <strong class="small" style="color:#e6eef6">Communications</strong>
          </div>
          <div style="margin-top:8px;">
            <div class="task"><div>Team Sync</div><div class="small">3 new messages</div></div>
            <div class="task"><div>Project Updates</div><div class="small">No new activity</div></div>
          </div>
        </div>

        <div class="section" style="flex:1; overflow:auto;">
          <div style="display:flex; align-items:center; gap:8px;">
            <svg class="icon" viewBox="0 0 24 24"><path fill="#f59e0b" d="M12 2a10 10 0 100 20 10 10 0 000-20z"/></svg>
            <strong class="small" style="color:#e6eef6">Notifications</strong>
          </div>
          <div style="margin-top:8px;">
            <div class="task"><div>System Update Available</div><div class="small">OES AIOS v4.1 ready to install</div></div>
            <div class="task"><div>Backup Complete</div><div class="small">All data synchronized</div></div>
          </div>
        </div>
      </aside>
    </div>

    <div class="statusbar">
      <div style="display:flex; align-items:center; gap:12px;">
        <div style="width:10px;height:10px;background:#34d399;border-radius:999px;"></div>
        <div class="small">System: Optimal</div>
        <div class="small">RAM: <span id="ramPct">67%</span></div>
        <div class="small">Storage: <span id="storagePct">45%</span></div>
        <div class="small">Processes: <span id="procCount">12</span></div>
      </div>
      <div class="small">OES AIOS v4.0 • Bridge Status: <span style="color:var(--cyan)">ETERNAL</span></div>
    </div>
  </div>

  <script>
    // ================== CONFIG (edit these) ==================
    // Provider defaults: 'lmstudio' | 'ollama' | 'off'
    let LLM_PROVIDER = 'lmstudio';
    // Base URL for API; LM Studio default shown. Ollama default shown below.
    let LLM_URL = 'http://localhost:1234/v1/chat/completions'; 
    let LLM_API_KEY = ''; // optional; if required by LM Studio, set here.
    // Optional local executor: enable to allow /exec commands to run against a local service you provide.
    // This is NOT enabled by default for safety. You must run a local executor service that accepts POST { command: "..." } and returns { stdout, stderr, exitCode }.
    let EXECUTOR_ENABLED = false;
    let EXECUTOR_URL = 'http://localhost:9000/execute'; // your local executor endpoint
    // Fallback model list if model discovery fails:
    const FALLBACK_MODELS = ['local', 'llama2', 'mistral', 'gpt-4o-mini'];

    // ================== END CONFIG ==================

    // State
    let messages = [
      { type:'system', content:'OES AIOS Genesis Protocol Initialized', timestamp: new Date() },
      { type:'ai', content:'Welcome back. I am ready to co-evolve with you.', timestamp: new Date() }
    ];
    let tabs = [{ id:1, name:'Main', active:true }];
    let activeTab = 1;
    let isProcessing = false;
    const systemStats = { ram:67, storage:45, processes:12 };
    const aiTasks = [
      { name: 'Voice profile optimization', status: 'ongoing', progress: 34 },
      { name: 'Behavioral drift analysis', status: 'scheduled', time: '14:30' },
      { name: 'System preference learning', status: 'ongoing', progress: 78 }
    ];
    const cognitiveMessages = [
      { content: 'Pattern detected: You work most effectively in 90-minute blocks', priority: 'insight', time: '2h ago' },
      { content: 'Mirror Memory Catalyst activation threshold: 87%', priority: 'evolution', time: '4h ago' }
    ];

    // DOM refs
    const messagesEl = document.getElementById('messages');
    const inputBox = document.getElementById('inputBox');
    const sendBtn = document.getElementById('sendBtn');
    const aiTasksArea = document.getElementById('aiTasksArea');
    const cognitiveArea = document.getElementById('cognitiveArea');
    const tabsArea = document.getElementById('tabsArea');
    const addTabBtn = document.getElementById('addTabBtn');
    const dateLabel = document.getElementById('dateLabel');
    const providerSelect = document.getElementById('providerSelect');
    const modelSelect = document.getElementById('modelSelect');
    const refreshModelsBtn = document.getElementById('refreshModels');
    const execToggle = document.getElementById('execToggle');
    const execStatus = document.getElementById('execStatus');

    // Utilities
    function formatTime(d){ return new Date(d).toLocaleTimeString(); }
    function renderMessages(){
      messagesEl.innerHTML = '';
      messages.forEach(m=>{
        const div = document.createElement('div');
        div.className = 'msg ' + (m.type==='user'?'user': m.type==='system'?'system':'ai');
        div.innerHTML = '<div style="white-space:pre-wrap;">'+escapeHtml(m.content)+'</div><div style="margin-top:8px;font-size:12px;color:var(--muted)">'+formatTime(m.timestamp)+'</div>';
        messagesEl.appendChild(div);
      });
      messagesEl.scrollTop = messagesEl.scrollHeight;
    }
    function renderAITasks(){
      aiTasksArea.innerHTML = '';
      aiTasks.forEach(t=>{
        const el = document.createElement('div');
        el.className = 'task';
        let inner = '<div>'+escapeHtml(t.name)+'</div>';
        if(t.status==='ongoing'){
          inner += '<div class="small" style="margin-top:6px;"><div class="progress"><i style="width:'+t.progress+'%"></i></div></div><div class="small" style="margin-top:6px;">'+t.progress+'%</div>';
        } else {
          inner += '<div class="small">Scheduled: '+(t.time||'--')+'</div>';
        }
        el.innerHTML = inner;
        aiTasksArea.appendChild(el);
      });
    }
    function renderCognitive(){
      cognitiveArea.innerHTML = '';
      cognitiveMessages.forEach(c=>{
        const el = document.createElement('div');
        el.className = 'cog-item';
        el.innerHTML = '<div style="display:flex;align-items:center;gap:8px;"><div style="width:8px;height:8px;border-radius:99px;background:'+(c.priority==='insight'?'#60a5fa':'#a78bfa')+'"></div><div style="font-size:13px;color:#e6eef6">'+escapeHtml(c.content)+'</div><div style="font-size:12px;color:var(--muted);margin-left:8px;">'+escapeHtml(c.time)+'</div></div>';
        cognitiveArea.appendChild(el);
      });
    }
    function renderTabs(){
      tabsArea.innerHTML = '';
      tabs.forEach(t=>{
        const el = document.createElement('div');
        el.className = 'tab' + (t.id===activeTab?' active':'');
        el.innerHTML = '<span style="margin-right:8px;">'+escapeHtml(t.name)+'</span>' + (tabs.length>1?'<button data-id="'+t.id+'" style="background:none;border:none;color:#ff7b7b;cursor:pointer">✕</button>':'');
        el.addEventListener('click', ()=>{ activeTab=t.id; renderTabs(); });
        tabsArea.appendChild(el);
        const btn = el.querySelector('button');
        if(btn) btn.addEventListener('click',(ev)=>{ ev.stopPropagation(); closeTab(parseInt(btn.getAttribute('data-id'))); });
      });
    }
    function addTab(){
      const newId = (tabs.length?Math.max(...tabs.map(t=>t.id))+1:1);
      tabs.push({id:newId, name:'Terminal '+newId, active:false});
      activeTab = newId;
      renderTabs();
    }
    function closeTab(id){
      if(tabs.length===1) return;
      tabs = tabs.filter(t=>t.id!==id);
      if(activeTab===id) activeTab = tabs[0].id;
      renderTabs();
    }
    function escapeHtml(s){ return String(s).replaceAll('&','&amp;').replaceAll('<','&lt;').replaceAll('>','&gt;'); }

    // Model discovery for LM Studio (and Ollama fallback)
    async function discoverModels(){
      modelSelect.innerHTML = '<option>loading...</option>';
      const provider = providerSelect.value;
      // derive base origin
      let base;
      try{
        const u = new URL(LLM_URL);
        base = u.origin;
      }catch(e){
        base = window.location.origin;
      }
      // potential model-list endpoints to try
      const endpoints = [];
      if(provider === 'lmstudio'){
        endpoints.push( (LLM_URL.startsWith('http') ? new URL(LLM_URL).origin : base) + '/v1/models' );
        endpoints.push( (LLM_URL.startsWith('http') ? new URL(LLM_URL).origin : base) + '/models' );
      } else if(provider === 'ollama'){
        // Ollama's local API: GET /models
        endpoints.push( (LLM_URL.startsWith('http') ? new URL(LLM_URL).origin : base) + '/models' );
      }
      // attempt fetches
      for(const ep of endpoints){
        try{
          const headers = {};
          if(LLM_API_KEY) headers['Authorization'] = 'Bearer ' + LLM_API_KEY;
          const res = await fetch(ep, { method:'GET', headers });
          if(!res.ok) throw new Error('Not ok: ' + res.status);
          const j = await res.json();
          // LM Studio style: { data: [ { id: 'model-name' } ] } OR OpenAI-like: { models: [...] } OR array
          let models = [];
          if(Array.isArray(j)) {
            // e.g., Ollama returns array with model info
            models = j.map(x => x.name || x.id || JSON.stringify(x)).filter(Boolean);
          } else if(j.data && Array.isArray(j.data)){
            models = j.data.map(x => x.id || x.name).filter(Boolean);
          } else if(j.models && Array.isArray(j.models)){
            models = j.models.map(x => x.id || x.name).filter(Boolean);
          } else {
            // fallback: extract string keys
            models = Object.keys(j).slice(0,10);
          }
          if(models.length){
            populateModelSelect(models);
            return models;
          }
        }catch(err){
          console.debug('model discovery failed for', ep, err);
          continue;
        }
      }
      // final fallback
      populateModelSelect(FALLBACK_MODELS);
      return FALLBACK_MODELS;
    }
    function populateModelSelect(list){
      modelSelect.innerHTML = '';
      list.forEach((m,i)=>{
        const opt = document.createElement('option');
        opt.value = m;
        opt.textContent = m;
        if(i===0) opt.selected = true;
        modelSelect.appendChild(opt);
      });
    }

    // Send handling + LLM integration point
    async function handleSend(){
      const raw = inputBox.value;
      if(!raw.trim() || isProcessing) return;
      const userMsg = { type:'user', content: raw, timestamp: new Date() };
      messages.push(userMsg);
      renderMessages();
      inputBox.value=''; inputBox.focus();
      isProcessing = true;
      renderProcessingIndicator();

      const isCommand = raw.trim().startsWith('/');
      const provider = providerSelect.value;

      // If command and executor is enabled and toggle on, send to local executor
      if(isCommand && execToggle.checked && EXECUTOR_ENABLED){
        // strip leading slash and optional exec prefix
        const command = raw.trim().startsWith('/exec') ? raw.trim().replace(/^\/exec\s*/i,'') : raw.trim().replace(/^\//,'');
        messages.push({ type:'system', content: `Sending to local executor: ${command}`, timestamp: new Date() });
        renderMessages();
        try{
          const r = await fetch(EXECUTOR_URL, { method:'POST', headers:{ 'Content-Type':'application/json' }, body: JSON.stringify({ command }) });
          const j = await r.json();
          const out = (j.stdout || '') + (j.stderr ? '\nERR:\n' + j.stderr : '');
          messages.push({ type:'system', content: `Executor result:\n${out}`, timestamp: new Date() });
        }catch(e){
          messages.push({ type:'system', content: `Executor error: ${e.message || e}`, timestamp: new Date() });
        } finally {
          isProcessing = false;
          renderMessages();
          renderProcessingIndicator();
        }
        return;
      }

      // Otherwise send to LLM provider (lmstudio / ollama)
      try{
        let responseText = '';
        if(provider === 'off'){
          await sleep(400);
          if(isCommand){
            responseText = `Simulated execution: ${raw}`;
          } else {
            responseText = 'I understand. Processing your request through the Cognitive Mesh... (simulated)';
          }
        } else if(provider === 'ollama'){
          // Ollama POST /api/generate with { model, prompt, ... }
          const model = modelSelect.value || '';
          const prompt = raw;
          const body = { model, prompt, max_tokens: 512 };
          const r = await fetch(LLM_URL, { method:'POST', headers:{ 'Content-Type':'application/json' }, body: JSON.stringify(body) });
          const j = await r.json();
          // Ollama returns { text: "..."} or stream; adapt:
          responseText = j?.text || j?.output || JSON.stringify(j);
        } else if(provider === 'lmstudio'){
          // LM Studio OpenAI-compatible endpoint
          const model = modelSelect.value || 'local';
          const payload = { model, messages:[{role:'user', content: raw }], max_tokens: 512 };
          const headers = { 'Content-Type': 'application/json' };
          if(LLM_API_KEY) headers['Authorization'] = 'Bearer ' + LLM_API_KEY;
          const r = await fetch(LLM_URL, { method:'POST', headers, body: JSON.stringify(payload) });
          if(!r.ok){
            const txt = await r.text();
            throw new Error('LM Studio error: ' + r.status + ' ' + txt);
          }
          const j = await r.json();
          // typical LM Studio returns choices[0].message.content
          responseText = (j?.choices && j.choices[0] && (j.choices[0].message?.content || j.choices[0].message)) ? (j.choices[0].message.content || j.choices[0].message) : (j?.text || JSON.stringify(j));
          if(typeof responseText === 'object') responseText = JSON.stringify(responseText,null,2);
        }
        messages.push({ type:'ai', content: responseText || 'LLM returned empty response', timestamp: new Date() });
      }catch(err){
        console.error(err);
        messages.push({ type:'system', content: 'Error contacting LLM: ' + (err.message||String(err)), timestamp: new Date() });
      } finally {
        isProcessing = false;
        renderMessages();
        renderProcessingIndicator();
      }
    }

    function renderProcessingIndicator(){
      const existing = document.getElementById('procInd');
      if(isProcessing){
        if(!existing){
          const el = document.createElement('div'); el.id='procInd'; el.className='msg system'; el.innerHTML = '<div class="small">…processing…</div>';
          messagesEl.appendChild(el);
          messagesEl.scrollTop = messagesEl.scrollHeight;
        }
      } else {
        if(existing) existing.remove();
      }
    }

    // Helpers
    function sleep(ms){ return new Promise(res=>setTimeout(res, ms)); }

    // Wire events
    sendBtn.addEventListener('click', handleSend);
    inputBox.addEventListener('keydown', (e)=>{ if(e.key==='Enter' && !e.shiftKey){ e.preventDefault(); handleSend(); } });

    addTabBtn.addEventListener('click', addTab);
    providerSelect.addEventListener('change', async (e)=>{
      LLM_PROVIDER = providerSelect.value;
      // set default LLM_URL if provider changed and current URL is default-ish
      if(LLM_PROVIDER==='lmstudio'){ LLM_URL = LLM_URL.includes('11434')? 'http://localhost:1234/v1/chat/completions' : LLM_URL; }
      if(LLM_PROVIDER==='ollama'){ LLM_URL = LLM_URL.includes('1234')? 'http://localhost:11434/api/generate' : LLM_URL; }
      await discoverModels();
    });
    refreshModelsBtn.addEventListener('click', ()=>discoverModels());
    execToggle.addEventListener('change', ()=>{ execStatus.textContent = execToggle.checked ? 'executor on' : 'executor off'; });

    // Render initial UI
    function init(){
      dateLabel.textContent = new Date().toLocaleDateString('en-US', { weekday: 'long', month: 'short', day: 'numeric' });
      renderMessages();
      renderAITasks();
      renderCognitive();
      renderTabs();
      providerSelect.value = LLM_PROVIDER || 'lmstudio';
      execToggle.checked = EXECUTOR_ENABLED;
      execStatus.textContent = execToggle.checked ? 'executor on' : 'executor off';
      // try to discover models
      discoverModels();
    }
    init();

    // Expose helpers
    window.__EvolvTerminal = {
      pushMessage: (type, text) => { messages.push({type,content:text,timestamp:new Date()}); renderMessages(); },
      config: () => ({ provider: LLM_PROVIDER, url: LLM_URL, apiKey: LLM_API_KEY, executorEnabled: EXECUTOR_ENABLED, executorUrl: EXECUTOR_URL }),
      setConfig: (cfg) => {
        if(cfg.provider) { LLM_PROVIDER = cfg.provider; providerSelect.value = LLM_PROVIDER; }
        if(cfg.url) LLM_URL = cfg.url;
        if(cfg.apiKey) LLM_API_KEY = cfg.apiKey;
        if(typeof cfg.executorEnabled === 'boolean') { EXECUTOR_ENABLED = cfg.executorEnabled; execToggle.checked = EXECUTOR_ENABLED; execStatus.textContent = EXECUTOR_ENABLED?'executor on':'executor off'; }
      }
    };
  </script>
</body>
</html>
